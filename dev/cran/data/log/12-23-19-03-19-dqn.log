band            : 10000000.0
buffer_size     : 100000
demand_max      : 10000000.0
demand_min      : 0.0
dir_log         : ./dev\cran\data\log
dir_mod         : ./dev\cran\data\mod
dir_sum         : ./dev\cran\data\sum
episodes        : 100
epochs          : 10
epsilon_final   : 0.01
epsilon_init    : 0.5
epsilon_steps   : 4000
eta             : 0.25
gamma           : 0.99
load_id         : None
lr              : 0.001
mini_batch      : 64
num_rrh         : 10
num_usr         : 8
observations    : 100
pow_gap         : 3.0
pow_on          : 6.8
pow_slp         : 4.3
pow_tsm         : 1.0
random_seed     : 10000
run_id          : 12-23-19-03-19
save_ep         : 20
tests           : 10
theta_2         : 6.3095734448e-14
tm              : 1
update          : 8
| Episode: 20 | Demand: [0.905 0.869 0.494 0.401 0.819 0.946 0.084 0.542] | Epsilon: 0.4975 | Agent-steps: 168 | Length: before 168 after 164 | Ep-max-reward: 0.6550 | Ep-min-reward: 0.7305 | Ep-rnd-reward: 4 0.8645 | Ep-reward: 0.8473 | Ep-max-power: 68.0978 | Ep-min-power: 63.1511 | Ep-rnd-power: 54.3733 | Ep-power: 55.5016 | Num-rrh-on: 5 | Ep-action: [(0, 2), (1, 2), (2, 79), (3, 1), (4, 1), (5, 5), (6, 6), (7, 4), (8, 4), (9, 8), (10, 2), (11, 8), (12, 5), (13, 5), (14, 2), (15, 3), (16, 3), (17, 8), (18, 3), (19, 4), (20, 13)] | Init-state: 1-1-1-1-1-1-1-1-1-1 | Final-state: 0-1-0-1-1-0-0-1-0-1
| Episode: 40 | Demand: [0.229 0.087 0.468 0.05  0.351 0.726 0.867 0.625] | Epsilon: 0.4951 | Agent-steps: 361 | Length: before 193 after 192 | Ep-max-reward: 0.6549 | Ep-min-reward: 0.7303 | Ep-rnd-reward: 3 0.8679 | Ep-reward: 0.7982 | Ep-max-power: 68.1009 | Ep-min-power: 63.1680 | Ep-rnd-power: 54.1556 | Ep-power: 58.7199 | Num-rrh-on: 5 | Ep-action: [(0, 5), (1, 5), (2, 28), (3, 4), (4, 4), (5, 11), (6, 6), (7, 2), (8, 4), (9, 4), (10, 20), (11, 2), (12, 35), (13, 4), (14, 5), (15, 2), (16, 5), (17, 6), (18, 18), (19, 2), (20, 21)] | Init-state: 1-1-1-1-1-1-1-1-1-1 | Final-state: 1-0-0-1-1-1-1-0-0-0
| Episode: 60 | Demand: [0.592 0.768 0.307 0.537 0.045 0.194 0.273 0.472] | Epsilon: 0.4926 | Agent-steps: 482 | Length: before 121 after 111 | Ep-max-reward: 0.6552 | Ep-min-reward: 0.7310 | Ep-rnd-reward: 3 0.8741 | Ep-reward: 0.8351 | Ep-max-power: 68.0812 | Ep-min-power: 63.1163 | Ep-rnd-power: 53.7458 | Ep-power: 56.2979 | Num-rrh-on: 1 | Ep-action: [(0, 6), (1, 52), (2, 2), (3, 3), (4, 4), (5, 1), (6, 5), (7, 5), (8, 1), (9, 5), (10, 7), (11, 11), (12, 1), (13, 4), (14, 1), (15, 1), (16, 1), (17, 4), (18, 2), (19, 1), (20, 4)] | Init-state: 1-1-1-1-1-1-1-1-1-1 | Final-state: 0-0-0-0-0-0-0-0-0-1
| Episode: 80 | Demand: [0.314 0.611 0.716 0.076 0.002 0.573 0.64  0.496] | Epsilon: 0.4902 | Agent-steps: 676 | Length: before 194 after 193 | Ep-max-reward: 0.6550 | Ep-min-reward: 0.7308 | Ep-rnd-reward: 3 0.8531 | Ep-reward: 0.8181 | Ep-max-power: 68.0945 | Ep-min-power: 63.1325 | Ep-rnd-power: 55.1238 | Ep-power: 57.4139 | Num-rrh-on: 2 | Ep-action: [(0, 3), (1, 19), (2, 4), (3, 4), (4, 6), (5, 5), (6, 4), (7, 5), (8, 8), (9, 3), (10, 4), (11, 2), (12, 6), (13, 3), (14, 3), (15, 7), (16, 49), (17, 1), (18, 4), (19, 48), (20, 6)] | Init-state: 1-1-1-1-1-1-1-1-1-1 | Final-state: 0-0-0-0-1-0-0-0-1-0
| Episode: 100 | Demand: [0.953 0.669 0.108 0.311 0.279 0.711 0.484 0.237] | Epsilon: 0.4877 | Agent-steps: 876 | Length: before 200 after 200 | Ep-max-reward: 0.6550 | Ep-min-reward: 0.7305 | Ep-rnd-reward: 3 0.8744 | Ep-reward: 0.7600 | Ep-max-power: 68.0973 | Ep-min-power: 63.1533 | Ep-rnd-power: 53.7262 | Ep-power: 61.2201 | Num-rrh-on: 6 | Ep-action: [(0, 4), (1, 5), (2, 3), (3, 4), (4, 44), (5, 3), (6, 3), (7, 9), (8, 5), (9, 3), (10, 24), (11, 9), (12, 3), (13, 1), (14, 11), (15, 6), (16, 25), (17, 8), (18, 15), (19, 7), (20, 8)] | Init-state: 1-1-1-1-1-1-1-1-1-1 | Final-state: 0-1-1-0-1-0-1-0-1-1
