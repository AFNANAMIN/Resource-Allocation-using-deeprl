band            : 10000000.0
buffer_size     : 100000
demand_max      : 60000000.0
demand_min      : 50000000.0
dir_log         : ./dev\cran\data\log
dir_mod         : ./dev\cran\data\mod
dir_sum         : ./dev\cran\data\sum
episodes        : 100
epochs          : 10
epsilon_final   : 0.01
epsilon_init    : 0.5
epsilon_steps   : 4000
eta             : 0.25
gamma           : 0.99
load_id         : None
lr              : 0.001
mini_batch      : 64
num_rrh         : 8
num_usr         : 4
observations    : 100
pow_gap         : 3.0
pow_on          : 6.8
pow_slp         : 4.3
pow_tsm         : 1.0
random_seed     : 10000
run_id          : 11-10-15-49-41
save_ep         : 20
tests           : 10
theta_2         : 6.3095734448e-14
tm              : 1
update          : 8
| Episode: 20 | Demand: [5.146 5.358 5.538 5.419] | Epsilon: 0.4975 | Agent-steps: 26 | Length: before 26 after 6 | Ep-max-reward: 0.3750 | Ep-min-reward: 0.0000 | Ep-rnd-reward: 7 0.3179 | Ep-reward: 0.3675 | Ep-max-power: 69.7101 | Ep-min-power: 0.0000 | Ep-rnd-power: 72.7101 | Ep-power: 70.1087 | Num-rrh-on: 3 | Ep-action: [(0, 1), (1, 1), (2, 11), (3, 2), (4, 3), (5, 2), (9, 1), (12, 2), (14, 1), (15, 1), (16, 1)] | Init-state: 1-1-1-1-1-1-1-1 | Final-state: 0-0-0-1-0-1-1-0
| Episode: 40 | Demand: [5.327 5.367 5.332 5.472] | Epsilon: 0.4951 | Agent-steps: 50 | Length: before 24 after 4 | Ep-max-reward: 0.3810 | Ep-min-reward: 0.0000 | Ep-rnd-reward: 7 0.2876 | Ep-reward: 0.3810 | Ep-max-power: 69.3983 | Ep-min-power: 0.0000 | Ep-rnd-power: 74.2991 | Ep-power: 69.3983 | Num-rrh-on: 4 | Ep-action: [(1, 1), (2, 10), (3, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 2), (16, 1)] | Init-state: 1-1-1-1-1-1-1-1 | Final-state: 0-1-1-0-1-0-0-1
| Episode: 60 | Demand: [5.127 5.403 5.14  5.577] | Epsilon: 0.4926 | Agent-steps: 83 | Length: before 33 after 14 | Ep-max-reward: 0.4198 | Ep-min-reward: 0.0000 | Ep-rnd-reward: 7 0.3559 | Ep-reward: 0.3729 | Ep-max-power: 67.3582 | Ep-min-power: 0.0000 | Ep-rnd-power: 70.7148 | Ep-power: 69.8239 | Num-rrh-on: 5 | Ep-action: [(0, 1), (2, 17), (3, 1), (4, 2), (5, 3), (6, 1), (7, 2), (11, 1), (12, 3), (15, 2)] | Init-state: 1-1-1-1-1-1-1-1 | Final-state: 1-1-0-1-1-0-1-0
| Episode: 80 | Demand: [5.753 5.31  5.026 5.947] | Epsilon: 0.4902 | Agent-steps: 110 | Length: before 27 after 7 | Ep-max-reward: 0.4432 | Ep-min-reward: 0.0000 | Ep-rnd-reward: 7 0.4057 | Ep-reward: 0.4268 | Ep-max-power: 66.1307 | Ep-min-power: 0.0000 | Ep-rnd-power: 68.0994 | Ep-power: 66.9920 | Num-rrh-on: 5 | Ep-action: [(1, 1), (2, 13), (3, 2), (5, 2), (8, 1), (10, 4), (11, 1), (13, 2), (14, 1)] | Init-state: 1-1-1-1-1-1-1-1 | Final-state: 0-1-0-1-1-1-0-1
| Episode: 100 | Demand: [5.798 5.079 5.51  5.575] | Epsilon: 0.4877 | Agent-steps: 140 | Length: before 30 after 10 | Ep-max-reward: 0.4533 | Ep-min-reward: 0.0000 | Ep-rnd-reward: 7 0.4174 | Ep-reward: 0.4447 | Ep-max-power: 65.6005 | Ep-min-power: 0.0000 | Ep-rnd-power: 67.4858 | Ep-power: 66.0522 | Num-rrh-on: 7 | Ep-action: [(0, 1), (1, 1), (2, 13), (4, 6), (5, 1), (6, 1), (10, 1), (12, 2), (13, 2), (14, 2)] | Init-state: 1-1-1-1-1-1-1-1 | Final-state: 0-1-1-1-1-1-1-1
