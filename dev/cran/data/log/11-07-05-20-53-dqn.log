band            : 10000000.0
buffer_size     : 100000
demand_max      : 10
demand_min      : 0
dir_log         : ./dev\cran\data\log
dir_mod         : ./dev\cran\data\mod
dir_sum         : ./dev\cran\data\sum
episodes        : 5000
epochs          : 3
epsilon_final   : 0.01
epsilon_init    : 0.5
epsilon_steps   : 4000
eta             : 0.25
gamma           : 0.99
load_id         : None
lr              : 0.001
mini_batch      : 64
num_rrh         : 6
num_usr         : 3
observations    : 100
pow_gap         : 3.0
pow_on          : 6.8
pow_slp         : 4.3
pow_tsm         : 1.0
random_seed     : 10000
run_id          : 11-07-05-20-53
save_ep         : 20
tests           : 1000
theta_2         : 6.3095734448e-14
tm              : 1
update          : 8
| Episode: 20 | Demand: [0. 0. 0.] | Epsilon: 0.4975 | Agent-steps: 60 | Length: before 60 after 60 | Ep-max-reward: 0.6835 | Ep-min-reward: 0.8734 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.8181 | Ep-max-power: 40.8000 | Ep-min-power: 33.3000 | Ep-rnd-power: 28.3000 | Ep-power: 35.4833 | Num-rrh-on: 3 | Ep-action: [(2, 5), (3, 1), (4, 2), (5, 7), (6, 16), (7, 4), (8, 1), (9, 9), (10, 4), (11, 9), (12, 2)] | Init-state: 1-1-1-1-1-1 | Final-state: 1-0-1-1-0-0
| Episode: 40 | Demand: [0. 0. 0.] | Epsilon: 0.4951 | Agent-steps: 120 | Length: before 60 after 60 | Ep-max-reward: 0.6835 | Ep-min-reward: 0.8734 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.8762 | Ep-max-power: 40.8000 | Ep-min-power: 33.3000 | Ep-rnd-power: 28.3000 | Ep-power: 33.1917 | Num-rrh-on: 3 | Ep-action: [(0, 5), (1, 3), (2, 1), (3, 2), (4, 5), (5, 1), (6, 6), (7, 4), (8, 3), (9, 4), (11, 24), (12, 2)] | Init-state: 1-1-1-1-1-1 | Final-state: 0-1-1-0-1-0
| Episode: 60 | Demand: [0. 0. 0.] | Epsilon: 0.4926 | Agent-steps: 180 | Length: before 60 after 60 | Ep-max-reward: 0.6835 | Ep-min-reward: 0.8734 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.8675 | Ep-max-power: 40.8000 | Ep-min-power: 33.3000 | Ep-rnd-power: 28.3000 | Ep-power: 33.5333 | Num-rrh-on: 2 | Ep-action: [(0, 3), (1, 3), (2, 1), (3, 3), (4, 10), (5, 2), (6, 2), (7, 3), (8, 5), (9, 6), (10, 4), (11, 16), (12, 2)] | Init-state: 1-1-1-1-1-1 | Final-state: 0-0-1-0-0-1
| Episode: 80 | Demand: [0. 0. 0.] | Epsilon: 0.4902 | Agent-steps: 240 | Length: before 60 after 60 | Ep-max-reward: 0.6835 | Ep-min-reward: 0.8734 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.8399 | Ep-max-power: 40.8000 | Ep-min-power: 33.3000 | Ep-rnd-power: 28.3000 | Ep-power: 34.6250 | Num-rrh-on: 3 | Ep-action: [(0, 1), (1, 1), (2, 1), (4, 7), (5, 2), (6, 1), (7, 25), (9, 4), (10, 5), (11, 13)] | Init-state: 1-1-1-1-1-1 | Final-state: 0-1-1-0-0-1
| Episode: 100 | Demand: [0. 0. 0.] | Epsilon: 0.4877 | Agent-steps: 300 | Length: before 60 after 60 | Ep-max-reward: 0.6835 | Ep-min-reward: 0.8734 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.8681 | Ep-max-power: 40.8000 | Ep-min-power: 33.3000 | Ep-rnd-power: 28.3000 | Ep-power: 33.5083 | Num-rrh-on: 4 | Ep-action: [(1, 9), (2, 4), (3, 2), (4, 2), (5, 1), (6, 3), (7, 19), (8, 6), (9, 7), (10, 3), (11, 1), (12, 3)] | Init-state: 1-1-1-1-1-1 | Final-state: 0-1-1-1-1-0
